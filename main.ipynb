{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News Detection with NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resham Gala / Javier Granda / Theo Tortorici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial data reading and preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('fake_or_real_news_training.csv', index_col=\"ID\", encoding='utf-8')\n",
    "test = pd.read_csv('fake_or_real_news_test.csv', index_col=\"ID\" , encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking a look to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8476</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10294</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10142</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "ID                                                         \n",
       "8476                        You Can Smell Hillary’s Fear   \n",
       "10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "3608         Kerry to go to Paris in gesture of sympathy   \n",
       "10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "875     The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                    text label   X1   X2  \n",
       "ID                                                                        \n",
       "8476   Daniel Greenfield, a Shillman Journalism Fello...  FAKE  NaN  NaN  \n",
       "10294  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  NaN  NaN  \n",
       "3608   U.S. Secretary of State John F. Kerry said Mon...  REAL  NaN  NaN  \n",
       "10142  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  NaN  NaN  \n",
       "875    It's primary day in New York and front-runners...  REAL  NaN  NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3999 entries, 8476 to 9673\n",
      "Data columns (total 5 columns):\n",
      "title    3999 non-null object\n",
      "text     3999 non-null object\n",
      "label    3999 non-null object\n",
      "X1       33 non-null object\n",
      "X2       2 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 187.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10498</th>\n",
       "      <td>September New Homes Sales Rise——-Back To 1992 ...</td>\n",
       "      <td>September New Homes Sales Rise Back To 1992 Le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>Why The Obamacare Doomsday Cult Can't Admit It...</td>\n",
       "      <td>But when Congress debated and passed the Patie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>Sanders, Cruz resist pressure after NY losses,...</td>\n",
       "      <td>The Bernie Sanders and Ted Cruz campaigns vowe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4128</th>\n",
       "      <td>Surviving escaped prisoner likely fatigued and...</td>\n",
       "      <td>Police searching for the second of two escaped...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>Clinton and Sanders neck and neck in Californi...</td>\n",
       "      <td>No matter who wins California's 475 delegates ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "ID                                                         \n",
       "10498  September New Homes Sales Rise——-Back To 1992 ...   \n",
       "2439   Why The Obamacare Doomsday Cult Can't Admit It...   \n",
       "864    Sanders, Cruz resist pressure after NY losses,...   \n",
       "4128   Surviving escaped prisoner likely fatigued and...   \n",
       "662    Clinton and Sanders neck and neck in Californi...   \n",
       "\n",
       "                                                    text  \n",
       "ID                                                        \n",
       "10498  September New Homes Sales Rise Back To 1992 Le...  \n",
       "2439   But when Congress debated and passed the Patie...  \n",
       "864    The Bernie Sanders and Ted Cruz campaigns vowe...  \n",
       "4128   Police searching for the second of two escaped...  \n",
       "662    No matter who wins California's 475 delegates ...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2321 entries, 10498 to 4330\n",
      "Data columns (total 2 columns):\n",
      "title    2321 non-null object\n",
      "text     2321 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 54.4+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the dataset\n",
    "\n",
    "Dealing with the rows that have right shifted values, we delete these rows from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train[(train.label == 'REAL') | (train.label == 'FAKE')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FAKE', 'REAL'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the train and test data\n",
    "\n",
    "The idea is to train with the most amount of data available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_df = pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8476</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10294</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REAL</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10142</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REAL</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        X1   X2 label                                               text  \\\n",
       "ID                                                                         \n",
       "8476   NaN  NaN  FAKE  Daniel Greenfield, a Shillman Journalism Fello...   \n",
       "10294  NaN  NaN  FAKE  Google Pinterest Digg Linkedin Reddit Stumbleu...   \n",
       "3608   NaN  NaN  REAL  U.S. Secretary of State John F. Kerry said Mon...   \n",
       "10142  NaN  NaN  FAKE  — Kaydee King (@KaydeeKing) November 9, 2016 T...   \n",
       "875    NaN  NaN  REAL  It's primary day in New York and front-runners...   \n",
       "\n",
       "                                                   title  \n",
       "ID                                                        \n",
       "8476                        You Can Smell Hillary’s Fear  \n",
       "10294  Watch The Exact Moment Paul Ryan Committed Pol...  \n",
       "3608         Kerry to go to Paris in gesture of sympathy  \n",
       "10142  Bernie supporters on Twitter erupt in anger ag...  \n",
       "875     The Battle of New York: Why This Primary Matters  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining the title and text field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID\n",
       "8476     You Can Smell Hillary’s Fear Daniel Greenfield...\n",
       "10294    Watch The Exact Moment Paul Ryan Committed Pol...\n",
       "3608     Kerry to go to Paris in gesture of sympathy U....\n",
       "10142    Bernie supporters on Twitter erupt in anger ag...\n",
       "875      The Battle of New York: Why This Primary Matte...\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = combined_df.title + str(' ') + combined_df.text\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6287,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization and Lemmatization\n",
    "\n",
    "We used NLTK and wordnet dataset to build a function that tokenizes and does lemmatization on the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/javiergranda/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download() Download if needed\n",
    "nltk.download('wordnet')\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.pipeline import Pipeline\n",
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "#from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "#pipeline_object = Pipeline([('vect', CountVectorizer(tokenizer=LemmaTokenizer(), stop_words='english', ngram_range=(1, 3))),('tfidf', TfidfTransformer()),('svm-clf', SGDClassifier(loss='perceptron', penalty='l2',alpha=1e-3,max_iter=5,random_state=42))])\n",
    "#pipeline_object = pipeline_object.fit(df, train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term document matrix\n",
    "\n",
    "Building the term document matrix using sklearn CountVectorizer. Also removing stop words and combining bi-grams to capture word relationships. Also using previously defined tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6287, 3989224)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(tokenizer=LemmaTokenizer(), stop_words='english', ngram_range=(1, 3)) # remove english stop words and applying tri-grams\n",
    "X_combined_counts = count_vect.fit_transform(df) # using the text and title from training set\n",
    "X_combined_counts.shape # take a look at how many featuress where created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing sparcity with TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the tf–idf transform to re-weight the count features into floating point values suitable to use with the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3966, 3989224)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_combined_tfidf = tfidf_transformer.fit_transform(X_combined_counts)\n",
    "\n",
    "# Subsetting for train set\n",
    "X_train_tfidf = X_combined_tfidf[0:3966]\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2321, 3989224)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subsetting for test set\n",
    "X_test_tfidf = X_combined_tfidf[3966: ]\n",
    "X_test_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, train.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation of the Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Naive Bayes cross validated score is: 0.7975270109869541\n"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_score_nb = cross_val_score(\n",
    "    clf,\n",
    "    X_train_tfidf,\n",
    "    train.label,\n",
    "    cv = 3,\n",
    "    n_jobs = -1)\n",
    "\n",
    "print('Train - Naive Bayes cross validated score is: '+ str(np.mean(cv_score_nb)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Entropy Classifier (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "max_ent_lr = LogisticRegression(\n",
    "    penalty = 'l2', \n",
    "    tol = 0.0001, \n",
    "    C=1.0, \n",
    "    dual = False, \n",
    "    class_weight = None, \n",
    "    multi_class = 'multinomial', \n",
    "    solver = 'saga', \n",
    "    max_iter = 100, \n",
    "    n_jobs = 1).fit(X_train_tfidf, train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Max Entropy cross validated score is: 0.9074661474298094\n"
     ]
    }
   ],
   "source": [
    "cv_score_maxent = cross_val_score(\n",
    "    max_ent_lr,\n",
    "    X_train_tfidf,\n",
    "    train.label,\n",
    "    cv = 5,\n",
    "    n_jobs = -1)\n",
    "\n",
    "print('Train - Max Entropy cross validated score is: '+ str(np.mean(cv_score_maxent)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classifier \n",
    "\n",
    "Regularized linear model with stochastic gradient descent (SGD) learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "svm_clf = SGDClassifier(\n",
    "    loss='perceptron', \n",
    "    penalty='l2',\n",
    "    alpha=1e-3,\n",
    "    max_iter=5,\n",
    "    random_state=42).fit(X_train_tfidf, train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - SVM cross validated score is: 0.9392321350862872\n"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_score_svm = cross_val_score(\n",
    "    svm_clf,\n",
    "    X_train_tfidf,\n",
    "    train.label,\n",
    "    cv = 5,\n",
    "    n_jobs = -1)\n",
    "\n",
    "print('Train - SVM cross validated score is: '+ str(np.mean(cv_score_svm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE TRIED, UNSUCCESSFULLY, GRID SEARCH FOR HIPER-PARAMETER TUNING\n",
    "\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "#params_svm = {\n",
    "#    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "#    'tfidf__use_idf': (True, False),\n",
    "#    'clf-svm__alpha': (1e-2, 1e-3),}\n",
    "\n",
    "#gs_clf_svm = GridSearchCV(svm_clf, params_svm, n_jobs=-1)\n",
    "#gs_clf_svm = gs_clf_svm.fit(X_train_tfidf, train.label)\n",
    "#gs_clf_svm.best_score_\n",
    "#gs_clf_svm.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passive Agressive Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "pac = PassiveAggressiveClassifier(loss = 'squared_hinge').fit(X_train_tfidf, train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - PAC cross validated score is: 0.9389815164807939\n"
     ]
    }
   ],
   "source": [
    "cv_score_pac = cross_val_score(\n",
    "    pac,\n",
    "    X_train_tfidf,\n",
    "    train.label,\n",
    "    cv = 5,\n",
    "    n_jobs = -1)\n",
    "\n",
    "print('Train - PAC cross validated score is: '+ str(np.mean(cv_score_pac)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputting the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From all the above models, we see that SVM gives us the best result, thus we do predictions on the test data using the SVM Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FAKE', 'REAL', 'REAL', ..., 'FAKE', 'REAL', 'REAL'], dtype='<U4')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pred = svm_clf.predict(X_test_tfidf)\n",
    "final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10498</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2439</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>864</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4128</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>662</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID     0\n",
       "0  10498  FAKE\n",
       "1   2439  REAL\n",
       "2    864  REAL\n",
       "3   4128  REAL\n",
       "4    662  REAL"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the predictions into a dataframe\n",
    "final_df = pd.DataFrame(final_pred, index = test.index)\n",
    "final_df = final_df.reset_index()\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the submissions to a csv file\n",
    "final_df.to_csv('submission2.csv', sep=',', index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
